{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b91b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import html, dcc, dash_table\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import re\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import umap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "_conn = sqlite3.connect(\"airbnb_cartagena.sqlite\")\n",
    "df_attr = pd.read_sql_query(\"SELECT * FROM Attributes\", _conn, dtype={\"ID\": str})\n",
    "df_ts = pd.read_sql_query(\"SELECT * FROM TimeSeriesRaw\", _conn, dtype={\"ID\": str})\n",
    "df_ts_interp = pd.read_sql_query(\"SELECT * FROM TimeSeriesInterpolated\", _conn, dtype={\"ID\": str})\n",
    "_conn.close()\n",
    "\n",
    "red = \"#7e0d24\"  # dark red color for plots\n",
    "dates = [col for col in df_ts.columns if re.fullmatch(r\"\\d{1,2}/\\d{1,2}/\\d{4}\", col)]\n",
    "df_ts_interp = df_ts_interp.dropna(subset=dates, how=\"any\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011daf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_umap_and_distances():\n",
    "    # Drop some columns that are not needed\n",
    "    df_temp = df_attr.copy()\n",
    "    \"\"\"\n",
    "    df_temp=df_temp[[\n",
    "    'Name', 'Host', 'Base fee', 'Cleaning fee', 'URL', 'ID', 'latitude',\n",
    "    'longitude', 'Property type', 'Person capacity', 'accuracy_rating',\n",
    "    'checking_rating', 'cleanliness_rating', 'communication_rating',\n",
    "    'location_rating', 'value_rating', 'satisfaction_rating', 'Reviews',\n",
    "    'Bedrooms', 'Beds', 'Baths', 'City skyline view', 'Beach view',\n",
    "    'Sea/Lake view', 'Hot water', 'Jacuzzi', 'Shared pool', 'Shared gym',\n",
    "    'Patio or balcony', 'Outdoor furniture', 'Outdoor playground',\n",
    "    'Elevator', 'Carport', 'Dedicated workspace', 'AC', 'Heating', 'TV',\n",
    "    'Cable TV', 'Wifi', 'Laundry service', 'Kitchen', 'Dining table',\n",
    "    'Microwave', 'Dishes and silverware', 'Refrigerator', 'Stove', 'Keypad',\n",
    "    'Washer', 'Pets allowed', 'Crib', 'Security cameras', 'Lock on door']]\n",
    "    to_keep = [\n",
    "        \"Keypad\", \"Lock on door\", \"Smoke detector\", \"Security cameras\", \"AC\", \"Heating\", \n",
    "        \"Patio or balcony\", \"Stove\", \"Elevator\", \"Refrigerator\", \"Kitchen\", \"Wifi\", \n",
    "        \"TV\", \"Jacuzzi\", \"Carport\", \"Hot water\", \n",
    "    ]\n",
    "    df_temp = df_temp[[\"ID\", \"Base fee\"] + to_keep]\n",
    "    \"\"\"\n",
    "    df_temp = df_temp.iloc[:, :21]\n",
    "\n",
    "    # Melt time series data to long format\n",
    "    df_prices = (\n",
    "        df_ts_interp.copy()\n",
    "        .melt(id_vars=\"ID\", value_vars=dates, var_name=\"Date\", value_name=\"Value\")\n",
    "        .assign(Date=lambda d: pd.to_datetime(d[\"Date\"], dayfirst=True))\n",
    "    )\n",
    "\n",
    "    # Summarize per‐listing log‐price mean, std, and trend\n",
    "    def summarize(group):\n",
    "        #y = np.log1p(group[\"Value\"].replace(0, np.nan))  # Avoid log(0)\n",
    "        y = np.log1p(group[\"Value\"])\n",
    "        #y = group[\"Value\"]\n",
    "        days = (group[\"Date\"] - group[\"Date\"].min()).dt.days.values.reshape(-1,1)\n",
    "        lr = LinearRegression().fit(days, y) if len(np.unique(days))>1 else None\n",
    "        return pd.Series({\n",
    "            \"price_mean\": y.mean(),\n",
    "            \"price_std\":  y.std(),\n",
    "            \"price_trend\": lr.coef_[0] if lr else 0.0\n",
    "        })\n",
    "    df_price_summary = (\n",
    "        df_prices\n",
    "        .groupby(\"ID\", group_keys=False)\n",
    "        .apply(summarize)\n",
    "    )\n",
    "    df_merged = df_attr.merge(df_price_summary, on=\"ID\")\n",
    "\n",
    "    # Filter out near‐constant / low‐variance features\n",
    "    selector = VarianceThreshold(threshold=0.1)\n",
    "    X = selector.fit_transform(df_merged.select_dtypes(\"number\"))\n",
    "    to_keep = df_merged.select_dtypes(\"number\").columns[selector.get_support()]\n",
    "\n",
    "    # Drop highly correlated (>0.9)\n",
    "    df_reduced = pd.DataFrame(X, columns=to_keep)\n",
    "    corr = df_reduced.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape, dtype=bool), k=1))\n",
    "    to_drop = [c for c in upper.columns if (upper[c] > 0.9).any()]\n",
    "    df_space = df_reduced.drop(columns=to_drop)\n",
    "\n",
    "    # Scale + UMAP embedding\n",
    "    X_scaled = StandardScaler().fit_transform(df_space)\n",
    "    umap_proj = umap.UMAP(n_components=3, n_neighbors=30, min_dist=0.1, random_state=69).fit_transform(X_scaled)\n",
    "\n",
    "    # Build distance matrix and UMAP space DataFrame\n",
    "    df_space = df_merged.loc[df_space.index, ['ID','Base fee']].reset_index(drop=True)\n",
    "    df_space[['UMAP1','UMAP2','UMAP3']] = umap_proj\n",
    "    dist_matrix = squareform(pdist(df_space.drop(columns=[\"ID\", 'Base fee']).values, metric=\"euclidean\"))\n",
    "    df_dist = pd.DataFrame(dist_matrix, index=df_space['ID'], columns=df_space['ID'])\n",
    "    \n",
    "    return df_space, df_dist, dist_matrix, df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fbe1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_space, df_dist, dist_matrix, df_prices = build_umap_and_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c1531",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea10cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV accuracy: [0.75  0.625 0.625 0.938 0.533]\n",
      "Mean CV accuracy: 0.694\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best CV score: 0.812\n",
      "Best params:     {'clf__colsample_bytree': 0.7, 'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 100, 'clf__subsample': 0.9}\n",
      "Hold-out accuracy: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.88      1.00      0.93         7\n",
      "         Low       1.00      1.00      1.00         7\n",
      "         Mid       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.96      0.94      0.95        20\n",
      "weighted avg       0.96      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, re\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import umap, gudhi as gd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1) LOAD DATA FROM SQLITE\n",
    "_conn = sqlite3.connect(\"airbnb_cartagena.sqlite\")\n",
    "df_attr      = pd.read_sql(\"SELECT * FROM Attributes\", _conn, dtype={\"ID\": str})\n",
    "df_ts_interp = pd.read_sql(\"SELECT * FROM TimeSeriesInterpolated\", _conn, dtype={\"ID\": str})\n",
    "_conn.close()\n",
    "dates = [c for c in df_ts_interp.columns if re.fullmatch(r\"\\d{1,2}/\\d{1,2}/\\d{4}\", c)]\n",
    "df_ts_interp = df_ts_interp.dropna(subset=dates).reset_index(drop=True)\n",
    "df_attr = df_attr.set_index(\"ID\").reindex(df_ts_interp[\"ID\"].values).copy() # reindex attributes to match the time-series rows\n",
    "\n",
    "# 2) PRICE‐TIER TARGET\n",
    "df_attr[\"price_tier\"] = pd.qcut(df_attr[\"Base fee\"], 3, labels=[\"Low\",\"Mid\",\"High\"])\n",
    "\n",
    "# 3) TIME‐SERIES SUMMARY FEATURES\n",
    "def make_ts(df, dates):\n",
    "    rows = []\n",
    "    for vals in df[dates].values.astype(float):\n",
    "        y = np.log1p(vals)\n",
    "        d = np.arange(len(y))\n",
    "        coef = np.polyfit(d, y, 1)[0] if len(y)>1 else 0\n",
    "        s = pd.Series(y)\n",
    "        row = {\n",
    "            \"ts_mean\":  y.mean(),\n",
    "            \"ts_std\":   y.std(ddof=0),\n",
    "            \"ts_trend\": coef,\n",
    "            \"ts_spike\": (s.diff().abs()>0.1).sum() # type: ignore\n",
    "        }\n",
    "        for w in (7,14):\n",
    "            r = s.rolling(w, min_periods=1).agg([\"mean\",\"std\"]).iloc[-1]\n",
    "            row[f\"roll{w}_mean\"], row[f\"roll{w}_std\"] = r[\"mean\"], r[\"std\"]\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows, index=df[\"ID\"])\n",
    "df_ts_feats = make_ts(df_ts_interp, dates)\n",
    "\n",
    "# 4) UMAP “neighborhood” embedding on static + TS features\n",
    "static_num  = df_attr.select_dtypes(\"number\")\n",
    "static_bool = df_attr.select_dtypes(\"bool\").astype(int)\n",
    "X_umap       = pd.concat([static_num, static_bool, df_ts_feats], axis=1).fillna(0)\n",
    "proj         = umap.UMAP(n_components=2, random_state=42).fit_transform(X_umap)\n",
    "df_attr[\"UMAP1\"], df_attr[\"UMAP2\"] = proj[:,0], proj[:,1] # type: ignore\n",
    "\n",
    "# 5) Global TDA summaries on UMAP-distance matrix\n",
    "umap_coords = df_attr[[\"UMAP1\",\"UMAP2\"]].values\n",
    "dist_matrix = squareform(pdist(umap_coords, metric=\"euclidean\"))\n",
    "rips = gd.RipsComplex(distance_matrix=dist_matrix, # type: ignore\n",
    "                             max_edge_length=dist_matrix.max()) \n",
    "st = rips.create_simplex_tree(max_dimension=2)\n",
    "st.compute_persistence()\n",
    "pers = st.persistence()\n",
    "\n",
    "tda_feats = {\"H0_sum_life\":0.0, \"H1_sum_life\":0.0}\n",
    "for dim,(b,d) in pers:\n",
    "    life = (d if d!=float(\"inf\") else dist_matrix.max()) - b\n",
    "    if dim==0: tda_feats[\"H0_sum_life\"] += life\n",
    "    if dim==1: tda_feats[\"H1_sum_life\"] += life\n",
    "\n",
    "# broadcast across all listings\n",
    "df_tda_feats = pd.DataFrame([tda_feats]*len(df_attr),\n",
    "                            index=df_attr.index)\n",
    "\n",
    "# 6) Assemble everything\n",
    "df = df_attr.join(df_ts_feats).join(df_tda_feats)\n",
    "num_cols = df.select_dtypes(\"number\").columns\n",
    "df[num_cols] = df[num_cols].fillna(0)\n",
    "y        = df[\"price_tier\"]\n",
    "X_static = df[[\"Cleaning fee\",\"Bedrooms\",\"Baths\",\"UMAP1\",\"UMAP2\"]]\n",
    "X_ts     = df_ts_feats\n",
    "X_tda    = df_tda_feats\n",
    "X_amen   = df.select_dtypes(\"bool\").astype(int)\n",
    "\n",
    "# 7) Pipeline + model\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\",  Pipeline([(\"impute\",SimpleImputer()),(\"scale\",StandardScaler())]),\n",
    "     list(X_static)+list(X_ts)+list(X_tda)),\n",
    "    (\"amen\", OneHotEncoder(drop=\"first\"), X_amen.columns.tolist())\n",
    "])\n",
    "model = Pipeline([\n",
    "    (\"prep\", pre),\n",
    "    (\"clf\",  XGBClassifier(\n",
    "        n_estimators=200, max_depth=4, learning_rate=0.05,\n",
    "        use_label_encoder=False, eval_metric=\"mlogloss\", random_state=0\n",
    "    ))\n",
    "])\n",
    "le    = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "# 8) 5‐fold CV\n",
    "cv     = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "X_all  = pd.concat([X_static, X_ts, X_tda, X_amen], axis=1)\n",
    "scores = cross_val_score(model, X_all, y_enc, cv=cv, scoring=\"accuracy\")\n",
    "print(\"5-fold CV accuracy:\", np.round(scores,3))\n",
    "print(\"Mean CV accuracy:\", np.round(scores.mean(),3))\n",
    "\n",
    "# 8) hyperparameter tuning with 5-fold CV\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\":    [100, 200, 300],\n",
    "    \"clf__max_depth\":       [3, 4, 6],\n",
    "    \"clf__learning_rate\":   [0.01, 0.05, 0.1],\n",
    "    \"clf__subsample\":       [0.7, 0.9, 1.0],\n",
    "    \"clf__colsample_bytree\":[0.7, 0.9, 1.0],\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=69),\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(X_all, y_enc)\n",
    "\n",
    "print(\"Best CV score:\", round(grid.best_score_, 3))\n",
    "print(\"Best params:    \", grid.best_params_)\n",
    "\n",
    "# 9) Evaluate tuned model on hold-out split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_all, y_enc, stratify=y_enc, test_size=0.25, random_state=69\n",
    ")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_model.fit(X_tr, y_tr)\n",
    "y_pr = best_model.predict(X_te)\n",
    "\n",
    "print(\"Hold-out accuracy:\", round(accuracy_score(y_te, y_pr), 3))\n",
    "print(classification_report(\n",
    "    le.inverse_transform(y_te),\n",
    "    le.inverse_transform(y_pr),\n",
    "    target_names=le.classes_\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337aa02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# 10) Save the model and metrics\n",
    "y_pred = best_model.predict(X_te)\n",
    "y_score = best_model.predict_proba(X_te)\n",
    "report = classification_report(\n",
    "    le.inverse_transform(y_te),\n",
    "    le.inverse_transform(y_pred),\n",
    "    target_names=le.classes_,\n",
    "    output_dict=True\n",
    ")\n",
    "metrics_summary = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
    "    \"Value\": [\n",
    "        round(accuracy_score(y_te, y_pred), 3),\n",
    "        round(report[\"weighted avg\"][\"precision\"], 3), # type: ignore\n",
    "        round(report[\"weighted avg\"][\"recall\"], 3), # type: ignore\n",
    "        round(report[\"weighted avg\"][\"f1-score\"], 3) # type: ignore\n",
    "    ]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_summary)\n",
    "metrics_df.to_csv(\"models/model1/price_tier_metrics.csv\", index=False)\n",
    "\n",
    "# 11) Confusion matrix\n",
    "cm = confusion_matrix(y_te, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "cm_df.to_csv(\"models/model1/price_tier_confusion_matrix.csv\")\n",
    "\n",
    "# 12) Precision-Recall curves\n",
    "pr_colors = [\"#d79c9c\", red, \"#c71a37\"]\n",
    "pr_traces = []\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    p, r, _ = precision_recall_curve((y_te==i).astype(int), y_score[:,i])\n",
    "    ap = average_precision_score((y_te==i).astype(int), y_score[:,i])\n",
    "    pr_traces.append(\n",
    "        go.Scatter(\n",
    "            x=r,\n",
    "            y=p,\n",
    "            mode=\"lines\",\n",
    "            name=f\"{cls} (AP={ap:.2f})\",\n",
    "            line=dict(color=pr_colors[i % len(pr_colors)])\n",
    "        )\n",
    "    )\n",
    "pr_layout = go.Layout(\n",
    "    title=\"Precision–Recall Curves by Class\",\n",
    "    template=\"plotly_dark\",\n",
    "    xaxis_title=\"Recall\",\n",
    "    yaxis_title=\"Precision\",\n",
    "    legend=dict(bgcolor=\"rgba(0,0,0,0)\")\n",
    ")\n",
    "pr_fig = go.Figure(data=pr_traces, layout=pr_layout)\n",
    "pr_fig.write_json(\"models/model1/price_tier_pr_curves.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb04dc",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6161b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best CV score: 0.962\n",
      "Best params:    {'log__clf__C': 1, 'rf__clf__max_depth': None, 'rf__clf__n_estimators': 100}\n",
      "\n",
      "=== Tuned Ensemble ===\n",
      "Test accuracy : 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     0.909     0.909        11\n",
      "           1      0.966     0.966     0.966        29\n",
      "\n",
      "    accuracy                          0.950        40\n",
      "   macro avg      0.937     0.937     0.937        40\n",
      "weighted avg      0.950     0.950     0.950        40\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  1]\n",
      " [ 1 28]]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import umap, gudhi as gd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1) LOAD DATA FROM SQLITE\n",
    "_conn = sqlite3.connect(\"airbnb_cartagena.sqlite\")\n",
    "df_attr       = pd.read_sql(\"SELECT * FROM Attributes\", _conn, dtype={\"ID\": str})\n",
    "df_ts_interp  = pd.read_sql(\"SELECT * FROM TimeSeriesInterpolated\", _conn, dtype={\"ID\": str})\n",
    "_conn.close()\n",
    "dates = [c for c in df_ts_interp.columns if re.fullmatch(r\"\\d{1,2}/\\d{1,2}/\\d{4}\", c)]\n",
    "df_ts_interp = df_ts_interp.dropna(subset=dates).reset_index(drop=True)\n",
    "df_attr      = df_attr.set_index(\"ID\").reindex(df_ts_interp[\"ID\"]).reset_index()\n",
    "\n",
    "# 2) TARGET: average of all *_rating ≥4.8\n",
    "rating_cols = [c for c in df_attr.columns if c.endswith(\"_rating\")]\n",
    "df_attr[\"is_superhost\"] = (df_attr[rating_cols].mean(axis=1) >= 4.8).astype(int)\n",
    "\n",
    "# 3) TIME‐SERIES SUMMARY FEATURES\n",
    "def make_ts(df, dates):\n",
    "    rows = []\n",
    "    for vals in df[dates].values.astype(float):\n",
    "        y = np.log1p(vals)\n",
    "        d = np.arange(len(y))\n",
    "        coef = np.polyfit(d, y, 1)[0] if len(y)>1 else 0\n",
    "        s = pd.Series(y)\n",
    "        r7  = s.rolling(7, 1).agg([\"mean\",\"std\"]).iloc[-1]\n",
    "        r14 = s.rolling(14,1).agg([\"mean\",\"std\"]).iloc[-1]\n",
    "        rows.append({\n",
    "            \"ts_mean\": y.mean(), \"ts_std\": y.std(ddof=0), \"ts_trend\": coef,\n",
    "            \"roll7_mean\": r7[\"mean\"], \"roll7_std\": r7[\"std\"],\n",
    "            \"roll14_mean\": r14[\"mean\"], \"roll14_std\": r14[\"std\"],\n",
    "            \"ts_spikes\": (s.diff().abs()>0.1).sum()\n",
    "        })\n",
    "    return pd.DataFrame(rows, index=df[\"ID\"])\n",
    "df_ts_feats = make_ts(df_ts_interp, dates)\n",
    "df_ts_feats.index = df_attr.index\n",
    "\n",
    "# 4) UMAP on static + ts\n",
    "static_num  = df_attr.select_dtypes(include=\"number\").drop(columns=[\"is_superhost\"])\n",
    "static_bool = df_attr.select_dtypes(include=\"bool\").astype(int)\n",
    "X_umap      = pd.concat([static_num, static_bool, df_ts_feats], axis=1).fillna(0)\n",
    "proj        = umap.UMAP(n_components=2, random_state=69).fit_transform(X_umap)\n",
    "df_attr[\"UMAP1\"], df_attr[\"UMAP2\"] = proj[:,0], proj[:,1] # type: ignore\n",
    "\n",
    "# 5) TDA on price volatility window=14\n",
    "def make_tda(df, dates, w=14):\n",
    "    rows=[]\n",
    "    for vals in df[dates].values.astype(float):\n",
    "        N = len(vals)-w+1\n",
    "        cloud = np.stack([vals[i:i+w] for i in range(N)])\n",
    "        st = gd.RipsComplex(points=cloud, max_edge_length=vals.ptp()) \\\n",
    "               .create_simplex_tree(max_dimension=2)\n",
    "        st.compute_persistence()\n",
    "        h0,h1 = [],[]\n",
    "        for dim,(b,e) in st.persistence():\n",
    "            life = ((e if e != np.inf else vals.ptp()) - b)\n",
    "            (h0 if dim==0 else h1).append(life)\n",
    "        rows.append({\n",
    "            \"H0_max\": max(h0, default=0), \"H0_sum\": sum(h0),\n",
    "            \"H1_max\": max(h1, default=0), \"H1_sum\": sum(h1), \"H1_cnt\": len(h1)\n",
    "        })\n",
    "    return pd.DataFrame(rows, index=df[\"ID\"])\n",
    "\n",
    "df_tda_feats = make_tda(df_ts_interp, dates)\n",
    "\n",
    "# 6) ASSEMBLE\n",
    "df = df_attr.set_index(\"ID\") \\\n",
    "    .join(df_ts_feats).join(df_tda_feats) \\\n",
    "    .fillna(0)\n",
    "y = df[\"is_superhost\"]\n",
    "X_num  = df.select_dtypes(include=\"number\").drop(columns=[\"is_superhost\"])\n",
    "X_amen = df.select_dtypes(include=\"bool\").astype(int)\n",
    "X_all  = pd.concat([X_num, X_amen], axis=1)\n",
    "\n",
    "# 7) SPLIT\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_all, y, stratify=y, test_size=0.5, random_state=69)\n",
    "\n",
    "# 8) PREPROCESSOR\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"impute\",SimpleImputer()),(\"scale\",StandardScaler())]),\n",
    "     X_num.columns),\n",
    "    (\"amen\", OneHotEncoder(drop=\"first\"), X_amen.columns)\n",
    "])\n",
    "\n",
    "# 9) Define ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"log\", Pipeline([(\"prep\", pre),\n",
    "                          (\"clf\", LogisticRegression(penalty=\"l1\", solver=\"saga\",\n",
    "                                                     max_iter=2000))])),\n",
    "        (\"rf\",  Pipeline([(\"prep\", pre),\n",
    "                          (\"clf\", RandomForestClassifier(random_state=69))]))\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "# 10) Hyperparameter tunning with 5-fold CV\n",
    "param_grid = {\n",
    "    \"log__clf__C\": [0.01, 0.1, 1, 10],\n",
    "    \"rf__clf__n_estimators\": [100, 200, 500],\n",
    "    \"rf__clf__max_depth\": [None, 5, 10],\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    ensemble,\n",
    "    param_grid,\n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=69),\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_all, y)\n",
    "print(\"Best CV score:\", round(grid.best_score_, 3))\n",
    "print(\"Best params:   \", grid.best_params_)\n",
    "\n",
    "# 12) Evaluate on hold-out\n",
    "best = grid.best_estimator_\n",
    "best.fit(X_tr, y_tr)\n",
    "y_pr = best.predict(X_te)\n",
    "print(\"\\n=== Tuned Ensemble ===\")\n",
    "print(\"Test accuracy :\", round(accuracy_score(y_te, y_pr), 3))\n",
    "print(classification_report(y_te, y_pr, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f842440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# 13) Save the model and metrics\n",
    "y_pred = best.predict(X_te)\n",
    "acc    = accuracy_score(y_te, y_pred)\n",
    "class_names = [\"Not Superhost\", \"Superhost\"]\n",
    "report = classification_report(\n",
    "    y_te,\n",
    "    y_pred,\n",
    "    target_names=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "metrics_summary = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
    "    \"Value\": [\n",
    "        round(acc, 3),\n",
    "        round(report[\"weighted avg\"][\"precision\"], 3), # type: ignore\n",
    "        round(report[\"weighted avg\"][\"recall\"],    3), # type: ignore\n",
    "        round(report[\"weighted avg\"][\"f1-score\"],  3), # type: ignore\n",
    "    ]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_summary)\n",
    "metrics_df.to_csv(\"models/model2/metrics_summary.csv\", index=False)\n",
    "\n",
    "# 14) Confusion matrix\n",
    "cm    = confusion_matrix(y_te, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "cm_df.to_csv(\"models/model2/confusion_matrix.csv\")\n",
    "\n",
    "# 15) Feature importances (from RF inside the ensemble)\n",
    "rf_pipeline = best.named_estimators_['rf']\n",
    "importances = rf_pipeline.named_steps['clf'].feature_importances_\n",
    "num_feats  = list(X_num.columns)\n",
    "amen_feats = list(X_amen.columns)\n",
    "all_feats  = num_feats + amen_feats\n",
    "fi_df = (\n",
    "    pd.DataFrame({\"feature\": all_feats, \"importance\": importances})\n",
    "      .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "#fi_df.to_csv(\"models/model2/feature_importances.csv\", index=False)\n",
    "# 16) Plot top 20 feature importances\n",
    "top_n = fi_df.head(20)\n",
    "fig   = px.bar(\n",
    "    top_n,\n",
    "    x=\"importance\",\n",
    "    y=\"feature\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 20 Feature Importances (RF)\",\n",
    "    labels={\"importance\":\"Importance\", \"feature\":\"\"},\n",
    "    template=\"plotly_dark\",\n",
    "    color_discrete_sequence=[red]\n",
    ")\n",
    "fig.update_layout(yaxis=dict(autorange=\"reversed\"), height=600)\n",
    "fig.write_json(\"models/model2/feature_importances.json\")\n",
    "\n",
    "# 17) ROC curve for Superhost classification\n",
    "y_score = best.predict_proba(X_te)[:, 1]   # probability of class “1”\n",
    "y_true  = y_te                            # 0/1 labels\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "roc_auc     = auc(fpr, tpr)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr,\n",
    "    y=tpr,\n",
    "    mode=\"lines\",\n",
    "    name=f\"Superhost (AUC={roc_auc:.2f})\",\n",
    "    line=dict(color=red, width=3),\n",
    "    showlegend=False\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1],\n",
    "    y=[0, 1],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"white\", width=1, dash=\"dash\"),\n",
    "    showlegend=False\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=f\"ROC Curve (AUC = {roc_auc:.2f})\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    template=\"plotly_dark\",\n",
    "    legend=dict(bgcolor=\"rgba(0,0,0,0)\"),\n",
    "    height=400\n",
    ")\n",
    "fig.write_json(\"models/model2/roc_curve.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "372ce313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#7e0d24",
          "width": 3
         },
         "mode": "lines",
         "name": "Superhost (AUC=0.98)",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARhdddNFFtz9GF1100UW3P0YXXXTRRcc/RhdddNFFxz8AAAAAAADwPw==",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAACWexphuaehPxphuacRlus/GmG5pxGW6z9HWO5phOXuP0dY7mmE5e4/AAAAAAAA8D8AAAAAAADwPw==",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "color": "white",
          "dash": "dash",
          "width": 1
         },
         "mode": "lines",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "height": 400,
        "legend": {
         "bgcolor": "rgba(0,0,0,0)"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC Curve (AUC = 0.98)"
        },
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "def model2_roc_curves():\n",
    "    \"\"\"\n",
    "    Load and return the ROC curve figure for model 2.\n",
    "    \"\"\"\n",
    "    fig = pio.read_json(\"models/model2/roc_curve.json\")\n",
    "    fig.update_layout(height=400)\n",
    "    return fig\n",
    "\n",
    "model2_roc_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Importance=%{x}<br>=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#7e0d24",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "T8AGWgnjxD+OFFhFxDu6P9FEQIwUfLk/QeN+/NRnuT+R368+PyGyP1fKjKm1yq4/cjVwNHL2qD+petEYt/CmP6+VE7alR6U/k8y+32yPoz8AWAFOqQWWP9MfI1OZFJQ/upvLbJ+rkj8Sga1lD9GQP53OV7ABT5A/2iq99cx4hz+UstT8va+FPwrRw3446YQ/8bXdEQcOgz/0D1hjsqiAPw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "value_rating",
          "communication_rating",
          "location_rating",
          "satisfaction_rating",
          "accuracy_rating",
          "checking_rating",
          "cleanliness_rating",
          "longitude",
          "latitude",
          "UMAP2",
          "H1_max",
          "Base fee",
          "H0_sum",
          "Cleaning fee",
          "H1_sum",
          "Security cameras",
          "UMAP1",
          "Microwave",
          "H0_max",
          "H1_cnt"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "b": 40,
         "l": 200,
         "r": 40,
         "t": 80
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 20 Feature Importances (Random Forest)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "def model2_feature_importances():\n",
    "    \"\"\"\n",
    "    Load the pre-computed feature-importances JSON and return\n",
    "    a dark-themed Plotly bar chart (top 20).\n",
    "    \"\"\"\n",
    "    # read the JSON you wrote out\n",
    "    fig = pio.read_json(\"models/model2/feature_importances.json\")\n",
    "    \n",
    "    # enforce our styling\n",
    "    fig.update_layout(\n",
    "        title=\"Top 20 Feature Importances (Random Forest)\",\n",
    "        template=\"plotly_dark\",\n",
    "        xaxis_title=\"Importance\",\n",
    "        yaxis_title=\"\",\n",
    "        margin=dict(l=200, r=40, t=80, b=40),\n",
    "        height=600,\n",
    "    )\n",
    "    # make sure the largest importance is at top\n",
    "    fig.update_yaxes(autorange=\"reversed\")\n",
    "    \n",
    "    return fig\n",
    "model2_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca6638",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e61786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import lightgbm as lgb\n",
    "import gudhi as gd\n",
    "\n",
    "def build_occupancy_dataset(\n",
    "    df_attr, df_ts, df_ts_interp, dates,\n",
    "    roll_window=7,\n",
    "    tda_edge=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns X (features) and y (sold_out flag) for each (ID, date) \n",
    "    excluding the first roll_window days.\n",
    "    \"\"\"\n",
    "    # 1) Build long tables\n",
    "    # a) raw availability flag\n",
    "    df_avail = (\n",
    "        df_ts\n",
    "        .melt(id_vars=\"ID\", value_vars=dates,\n",
    "              var_name=\"Date\", value_name=\"Price\")\n",
    "        .assign(Date=lambda d: pd.to_datetime(d[\"Date\"], dayfirst=True))\n",
    "    )\n",
    "    df_avail[\"sold_out\"] = df_avail[\"Price\"].isna().astype(int)\n",
    "    \n",
    "    # b) interpolated price for stats & TDA\n",
    "    df_int = (\n",
    "        df_ts_interp\n",
    "        .melt(id_vars=\"ID\", value_vars=dates,\n",
    "              var_name=\"Date\", value_name=\"InterpPrice\")\n",
    "        .assign(Date=lambda d: pd.to_datetime(d[\"Date\"], dayfirst=True))\n",
    "    )\n",
    "\n",
    "    # 2) Rolling features per listing\n",
    "    feats = []\n",
    "    for lid, group in df_avail.groupby(\"ID\"):\n",
    "        g = group.sort_values(\"Date\").set_index(\"Date\")\n",
    "        # rolling availability rate\n",
    "        g[\"roll_avail_rate\"] = 1 - g[\"sold_out\"].rolling(roll_window).mean()\n",
    "        # merge price stats\n",
    "        pi = df_int[df_int[\"ID\"]==lid].sort_values(\"Date\").set_index(\"Date\")\n",
    "        g = g.join(pi[\"InterpPrice\"])\n",
    "        g[\"roll_price_mean\"] = g[\"InterpPrice\"].rolling(roll_window).mean()\n",
    "        g[\"roll_price_std\"]  = g[\"InterpPrice\"].rolling(roll_window).std()\n",
    "        # TDA summary on the last window\n",
    "        # build the cloud once per date\n",
    "        if tda_edge is None:\n",
    "            tda_edge = g[\"InterpPrice\"].max() - g[\"InterpPrice\"].min()\n",
    "        h0, h1 = [], []\n",
    "        prices = g[\"InterpPrice\"].values\n",
    "        for i in range(len(prices)):\n",
    "            if i < roll_window-1:\n",
    "                h0.append(np.nan); h1.append(np.nan)\n",
    "            else:\n",
    "                window = prices[i-roll_window+1:i+1]\n",
    "                cloud = np.stack([window[j:j+roll_window] \n",
    "                                  for j in range(len(window)-roll_window+1+roll_window)])\n",
    "                # simplify: use the 1D window itself as cloud of shape (roll_window, roll_window)\n",
    "                cloud = np.stack([window]*roll_window).T\n",
    "                st = gd.RipsComplex(points=cloud, max_edge_length=tda_edge) \\\n",
    "                        .create_simplex_tree(max_dimension=2)\n",
    "                st.compute_persistence()\n",
    "                s0=s1=0.0\n",
    "                for dim,(b,d) in st.persistence():\n",
    "                    life = (d if d!=float(\"inf\") else tda_edge) - b\n",
    "                    if dim==0: s0+=life\n",
    "                    if dim==1: s1+=life\n",
    "                h0.append(s0); h1.append(s1)\n",
    "        g[\"tda_H0_sum\"] = h0\n",
    "        g[\"tda_H1_sum\"] = h1\n",
    "        \n",
    "        g[\"ID\"] = lid\n",
    "        feats.append(g.reset_index())\n",
    "    df_feat = pd.concat(feats, ignore_index=True)\n",
    "    \n",
    "    # 3) Seasonality\n",
    "    df_feat[\"dow\"]   = df_feat[\"Date\"].dt.weekday\n",
    "    df_feat[\"month\"] = df_feat[\"Date\"].dt.month\n",
    "    \n",
    "    # 4) Static attributes + amenity one-hots\n",
    "    dfA = df_attr.set_index(\"ID\")\n",
    "    static = dfA[[\"Cleaning fee\",\"Bedrooms\",\"Baths\"]]\n",
    "    amenities = dfA.select_dtypes(bool).astype(int)\n",
    "    ohe = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "    X_amen = pd.DataFrame(\n",
    "        ohe.fit_transform(amenities),\n",
    "        index=amenities.index,\n",
    "        columns=ohe.get_feature_names_out(amenities.columns)\n",
    "    )\n",
    "    static = pd.concat([static, X_amen], axis=1)\n",
    "    df_feat = df_feat.join(static, on=\"ID\")\n",
    "\n",
    "    # 5) Drop rows with any NaNs (warm-up window)\n",
    "    df_feat = df_feat.dropna(subset=[\n",
    "        \"roll_avail_rate\",\"roll_price_mean\",\"roll_price_std\",\n",
    "        \"tda_H0_sum\",\"tda_H1_sum\"\n",
    "    ])\n",
    "\n",
    "    # 6) Assemble X, y\n",
    "    y = df_feat[\"sold_out\"]\n",
    "    X = df_feat[[\n",
    "        \"roll_avail_rate\",\"roll_price_mean\",\"roll_price_std\",\n",
    "        \"tda_H0_sum\",\"tda_H1_sum\",\n",
    "        \"dow\",\"month\"\n",
    "    ] + static.columns.tolist()]\n",
    "    return X, y\n",
    "\n",
    "# --- use it ---\n",
    "X, y = build_occupancy_dataset(df_attr, df_ts, df_ts_interp, dates)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "# scale numeric columns\n",
    "num_cols = [\n",
    "    \"roll_avail_rate\",\"roll_price_mean\",\"roll_price_std\",\n",
    "    \"tda_H0_sum\",\"tda_H1_sum\"\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# --- train LightGBM ---\n",
    "clf = lgb.LGBMClassifier(n_estimators=200, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- evaluate ---\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8cc16",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebfe2058",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'RangeIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# compute and join\u001b[39;00m\n\u001b[1;32m     62\u001b[0m df_tda \u001b[38;5;241m=\u001b[39m compute_local_tda(df_space, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 3) Build feature matrix\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# numeric static features\u001b[39;00m\n\u001b[1;32m     68\u001b[0m num_feats \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaning_fee\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBedrooms\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeds\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaths\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_rating\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleanliness_rating\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunication_rating\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_rating\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_rating\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msatisfaction_rating\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     72\u001b[0m ]\n",
      "File \u001b[0;32m~/micromamba/envs/global_env/lib/python3.11/site-packages/pandas/core/frame.py:10757\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m  10747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10748\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10749\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10750\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10755\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10756\u001b[0m         )\n\u001b[0;32m> 10757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10765\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  10769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/global_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/global_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[1;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    890\u001b[0m )\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[0;32m~/micromamba/envs/global_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1142\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m left_ax\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1138\u001b[0m         right_ax, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[1;32m   1139\u001b[0m     )\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1142\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[43m_left_join_on_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_ax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_ax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_index \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[1;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[1;32m   1149\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/global_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2384\u001b[0m, in \u001b[0;36m_left_join_on_index\u001b[0;34m(left_ax, right_ax, join_keys, sort)\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Index\",\u001b[39;00m\n\u001b[1;32m   2381\u001b[0m     \u001b[38;5;66;03m# variable has type \"ndarray[Any, dtype[signedinteger[Any]]]\")\u001b[39;00m\n\u001b[1;32m   2382\u001b[0m     rkey \u001b[38;5;241m=\u001b[39m right_ax\u001b[38;5;241m.\u001b[39m_values  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m-> 2384\u001b[0m left_key, right_key, count \u001b[38;5;241m=\u001b[39m \u001b[43m_factorize_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2385\u001b[0m left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(\n\u001b[1;32m   2386\u001b[0m     left_key, right_key, count, sort\u001b[38;5;241m=\u001b[39msort\n\u001b[1;32m   2387\u001b[0m )\n\u001b[1;32m   2389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left_ax) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(left_indexer):\n\u001b[1;32m   2390\u001b[0m     \u001b[38;5;66;03m# if asked to sort or there are 1-to-many matches\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/global_env/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2561\u001b[0m, in \u001b[0;36m_factorize_keys\u001b[0;34m(lk, rk, sort)\u001b[0m\n\u001b[1;32m   2554\u001b[0m     rlab \u001b[38;5;241m=\u001b[39m rizer\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[1;32m   2555\u001b[0m         rk\u001b[38;5;241m.\u001b[39mto_numpy(na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mlk\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnumpy_dtype), mask\u001b[38;5;241m=\u001b[39mrk\u001b[38;5;241m.\u001b[39misna()\n\u001b[1;32m   2556\u001b[0m     )\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2558\u001b[0m     \u001b[38;5;66;03m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;66;03m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001b[39;00m\n\u001b[0;32m-> 2561\u001b[0m     llab \u001b[38;5;241m=\u001b[39m \u001b[43mrizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2562\u001b[0m     rlab \u001b[38;5;241m=\u001b[39m rizer\u001b[38;5;241m.\u001b[39mfactorize(rk)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m llab\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mintp), llab\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:3045\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64Factorizer.factorize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<stringsource>:663\u001b[0m, in \u001b[0;36mView.MemoryView.memoryview_cwrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<stringsource>:353\u001b[0m, in \u001b[0;36mView.MemoryView.memoryview.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'RangeIndex'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import gudhi as gd\n",
    "\n",
    "# 1) Prepare the joined DataFrame\n",
    "# --------------------------------\n",
    "# assume df_attr, df_space are already loaded (from build_umap_and_distances)\n",
    "# df_attr: contains ID, static features, boolean amenity columns, and either \"superhost\" or rating\n",
    "# df_space: contains ID, UMAP1, UMAP2, UMAP3\n",
    "\n",
    "# Merge on ID\n",
    "df = df_attr.merge(df_space[['ID','UMAP1','UMAP2','UMAP3']], on='ID')\n",
    "\n",
    "# Define target\n",
    "if 'superhost' in df.columns:\n",
    "    df['target'] = df['superhost'].astype(int)\n",
    "else:\n",
    "    df['target'] = (df['satisfaction_rating'] >= 4.8).astype(int)\n",
    "\n",
    "# 2) Build TDA summarizer over each listing's UMAP neighborhood\n",
    "# -------------------------------------------------------------\n",
    "def compute_local_tda(df_space, k=10, max_dim=1):\n",
    "    \"\"\"\n",
    "    For each listing in df_space, find its k nearest neighbors in UMAP space,\n",
    "    build a Rips complex on that small cloud, and return sum of lifetimes\n",
    "    in H0 and H1 as features.\n",
    "    \"\"\"\n",
    "    coords = df_space[['UMAP1','UMAP2','UMAP3']].values\n",
    "    nb = NearestNeighbors(n_neighbors=k, metric='euclidean').fit(coords)\n",
    "    dists, idxs = nb.kneighbors(coords)\n",
    "    \n",
    "    tda_feats = []\n",
    "    for i, neighbors in enumerate(idxs):\n",
    "        cloud = coords[neighbors]\n",
    "        # set max_edge to the max pairwise distance in this cloud\n",
    "        max_edge = np.max(pdist(cloud))\n",
    "        rips = gd.RipsComplex(points=cloud, max_edge_length=max_edge)\n",
    "        st = rips.create_simplex_tree(max_dimension=max_dim+1)\n",
    "        st.compute_persistence()\n",
    "        sum_life = {d:0.0 for d in range(max_dim+1)}\n",
    "        for dim, (b,d) in st.persistence():\n",
    "            life = (d if d!=float('inf') else max_edge) - b\n",
    "            if dim<=max_dim:\n",
    "                sum_life[dim] += life\n",
    "        tda_feats.append((sum_life[0], sum_life.get(1,0.0)))\n",
    "    \n",
    "    df_tda = pd.DataFrame(tda_feats, columns=['tda_H0_sum','tda_H1_sum'], index=df_space.index)\n",
    "    return df_tda\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# compute and join\n",
    "df_tda = compute_local_tda(df_space, k=10, max_dim=1)\n",
    "df = df.join(df_tda, on=df.index)\n",
    "\n",
    "# 3) Build feature matrix\n",
    "# ------------------------\n",
    "# numeric static features\n",
    "num_feats = [\n",
    "    'cleaning_fee','Bedrooms','Beds','Baths',\n",
    "    'accuracy_rating','cleanliness_rating','communication_rating',\n",
    "    'location_rating','value_rating','satisfaction_rating'\n",
    "]\n",
    "# amenities (bool → int)\n",
    "amen_cols = df_attr.select_dtypes(include='bool').columns.tolist()\n",
    "\n",
    "# pipeline: scale numeric, one-hot amenities, pass through UMAP coords & TDA feats\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_feats),\n",
    "    ('amen', OneHotEncoder(drop='first'), amen_cols),\n",
    "    ('umap', 'passthrough', ['UMAP1','UMAP2','UMAP3']),\n",
    "    ('tda', 'passthrough', ['tda_H0_sum','tda_H1_sum'])\n",
    "])\n",
    "\n",
    "X = df[num_feats + amen_cols + ['UMAP1','UMAP2','UMAP3','tda_H0_sum','tda_H1_sum']]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "# 4) Fit and evaluate models\n",
    "# ---------------------------\n",
    "\n",
    "models = {\n",
    "    \"Logistic L1\": LogisticRegression(penalty='l1', solver='saga', max_iter=2000, random_state=0),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    \"Linear SVM\": LinearSVC(max_iter=2000, random_state=0)\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a7a33",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355904ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import gudhi as gd\n",
    "\n",
    "# --- 1) Prepare target via volatility features ------------------------------\n",
    "\n",
    "# 4.3.0 from above\n",
    "def compute_volatility_features(df_ts_interp, dates, spike_thresh=0.1):\n",
    "    mat = df_ts_interp.set_index(\"ID\")[dates].astype(float)\n",
    "    mean = mat.mean(axis=1)\n",
    "    dev = mat.sub(mean, axis=0).div(mean, axis=0)\n",
    "    feats = pd.DataFrame({\n",
    "        'std_dev':    dev.std(axis=1),\n",
    "        'max_dev':    dev.abs().max(axis=1),\n",
    "        'spike_freq': (dev.abs()>spike_thresh).sum(axis=1)/dev.shape[1]\n",
    "    })\n",
    "    feats.index.name = 'ID'\n",
    "    return feats.round(3)\n",
    "\n",
    "feats = compute_volatility_features(df_ts_interp, dates)\n",
    "\n",
    "# Binarize around median\n",
    "median_std = feats['std_dev'].median()\n",
    "feats['target'] = (feats['std_dev'] > median_std).astype(int)  # 1 = volatile, 0 = stable\n",
    "\n",
    "# --- 2) Build periodicity feature: count of H1 loops in 7-day window -------\n",
    "\n",
    "def count_h1_loops(listing_id, window=7):\n",
    "    row = df_ts_interp.loc[df_ts_interp['ID']==listing_id, dates].values.flatten().astype(float)\n",
    "    N = len(row) - window + 1\n",
    "    if N <= 0: \n",
    "        return 0\n",
    "    # stack full sliding‐window cloud\n",
    "    cloud = np.stack([row[i:i+window] for i in range(N)])\n",
    "    rips = gd.RipsComplex(points=cloud, max_edge_length=np.ptp(row))\n",
    "    st = rips.create_simplex_tree(max_dimension=2)\n",
    "    st.compute_persistence()\n",
    "    # count H1 intervals\n",
    "    return sum(1 for dim,(b,d) in st.persistence() if dim==1 and d> b)\n",
    "\n",
    "feats['h1_count'] = [count_h1_loops(lid) for lid in feats.index]\n",
    "\n",
    "# --- 3) Assemble modeling DataFrame -----------------------------------------\n",
    "\n",
    "# static + time‐series: pull from df_attr and price‐summary\n",
    "df_price_summary = build_umap_and_distances()[-1] \\\n",
    "    .groupby(\"ID\").apply(lambda g: pd.Series({\n",
    "        'price_mean': np.log1p(g.Value).mean(),\n",
    "        'price_std':  np.log1p(g.Value).std(),\n",
    "        'price_trend': LinearRegression().fit(\n",
    "            ((g.Date-g.Date.min()).dt.days.values.reshape(-1,1)),\n",
    "            np.log1p(g.Value)\n",
    "        ).coef_[0]\n",
    "    }))\n",
    "df_base = df_attr.set_index('ID').join(df_price_summary).join(feats)\n",
    "\n",
    "# features lists\n",
    "num_feats = [\n",
    "    'cleaning_fee','Bedrooms','Beds','Baths',\n",
    "    'price_mean','price_std','price_trend',\n",
    "    'std_dev','max_dev','spike_freq','h1_count'\n",
    "]\n",
    "amen = df_attr.select_dtypes('bool').columns.tolist()\n",
    "\n",
    "X = df_base[num_feats + amen]\n",
    "y = df_base['target']\n",
    "\n",
    "# --- 4) Preprocessing + model pipeline -------------------------------------\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_feats),\n",
    "    ('amen', OneHotEncoder(drop='first'), amen)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'RF': RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    'XGB': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0)\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([('pre', pre), ('clf', clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465f475",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fffcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cdist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 1) Build our dataset ------------------------------------------------------\n",
    "\n",
    "WINDOW = 30\n",
    "\n",
    "# 1a) Extract last-30-day windows (normalized) + linear trend target\n",
    "records = []\n",
    "for idx, row in df_ts_interp.set_index(\"ID\").iterrows():\n",
    "    prices = row[dates].astype(float).values\n",
    "    if len(prices) < WINDOW: \n",
    "        continue\n",
    "    window = prices[-WINDOW:]\n",
    "    # normalize\n",
    "    window_norm = (window - window.mean()) / (window.std() + 1e-6)\n",
    "    # compute trend slope\n",
    "    x = np.arange(WINDOW).reshape(-1,1)\n",
    "    slope = np.polyfit(x.flatten(), window, 1)[0]\n",
    "    # discretize target\n",
    "    if slope > 0.01:\n",
    "        label = 2  # up\n",
    "    elif slope < -0.01:\n",
    "        label = 0  # down\n",
    "    else:\n",
    "        label = 1  # flat\n",
    "    records.append({\n",
    "        'ID': idx,\n",
    "        'window': window_norm,\n",
    "        'trend': label\n",
    "    })\n",
    "\n",
    "df_ws = pd.DataFrame(records)\n",
    "X_series = np.stack(df_ws['window'].values)        # shape (n_samples, 30)\n",
    "y = df_ws['trend'].values                          # 0=down,1=flat,2=up\n",
    "\n",
    "# train/test split\n",
    "X_train_s, X_test_s, y_train, y_test = train_test_split(\n",
    "    X_series, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 1b) Feature‐extraction for RF & k-NN: persistence summaries\n",
    "def extract_tda_features(windows, max_dim=1):\n",
    "    feats = []\n",
    "    for w in windows:\n",
    "        cloud = np.stack([w[i:i+max_dim+1] for i in range(len(w)-max_dim)])  # tiny embedding\n",
    "        rips = gd.RipsComplex(points=cloud, max_edge_length=np.ptp(w))\n",
    "        st = rips.create_simplex_tree(max_dimension=max_dim+1)\n",
    "        st.compute_persistence()\n",
    "        pairs = st.persistence()\n",
    "        # sum of lifetimes per dim\n",
    "        sums = {d: sum((d1-d0) for dd,(d0,d1) in pairs if dd==d and d1<np.inf) for d in range(max_dim+1)}\n",
    "        # count intervals\n",
    "        counts = {f'c{d}': sum(1 for dd,(_,_d1) in pairs if dd==d) for d in range(max_dim+1)}\n",
    "        feats.append([sums.get(d,0) for d in range(max_dim+1)] +\n",
    "                     [counts[f'c{d}'] for d in range(max_dim+1)])\n",
    "    cols = [f'sum_life_H{d}' for d in range(max_dim+1)] + [f'count_H{d}' for d in range(max_dim+1)]\n",
    "    return pd.DataFrame(feats, columns=cols)\n",
    "\n",
    "df_train_tda = extract_tda_features(X_train_s, max_dim=1)\n",
    "df_test_tda  = extract_tda_features(X_test_s,  max_dim=1)\n",
    "\n",
    "# --- 2) Random Forest on TDA features --------------------------------------\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, random_state=0))\n",
    "])\n",
    "rf_pipe.fit(df_train_tda, y_train)\n",
    "y_pred_rf = rf_pipe.predict(df_test_tda)\n",
    "print(\"=== Random Forest on TDA features ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))\n",
    "\n",
    "# --- 3) DTW + k-NN using raw windowed series -------------------------------\n",
    "\n",
    "# Precompute pairwise DTW distances between test and train\n",
    "# (for simplicity, here we approximate DTW by Euclidean on windows;\n",
    "# for real DTW use dtaidistance or fastdtw)\n",
    "dist_mat = cdist(X_test_s, X_train_s, metric='euclidean')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n",
    "knn.fit(dist_mat, y_train)  # note: sklearn expects fit(X, y) but with precomputed, X is distance matrix\n",
    "# To predict we need the distance from test to train again:\n",
    "dist_test = dist_mat\n",
    "y_pred_knn = knn.predict(dist_test)\n",
    "print(\"=== k-NN (approx. DTW) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn, digits=3))\n",
    "\n",
    "# --- 4) Simple 1D CNN on raw series -----------------------------------------\n",
    "\n",
    "# reshape for CNN: (batch, time, 1)\n",
    "X_train_c = X_train_s[..., np.newaxis]\n",
    "X_test_c  = X_test_s[..., np.newaxis]\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(WINDOW,1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(X_train_c, y_train, validation_split=0.1, epochs=20, batch_size=32, verbose=2)\n",
    "\n",
    "loss, acc = cnn.evaluate(X_test_c, y_test, verbose=0)\n",
    "print(\"\\n=== 1D CNN ===\")\n",
    "print(f\"Test accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77640e",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f109d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 0) Prepare “ground-truth” segments via your unsupervised clusters -----\n",
    "\n",
    "# am: DataFrame shape (n_listings, n_amenities) with 0/1\n",
    "# labels: Series of cluster labels (strings) indexed by listing ID\n",
    "am, labels = cluster_by_amenities(k=4)\n",
    "\n",
    "# Build a single DataFrame of features + target\n",
    "# Start with amenities one-hots:\n",
    "df_seg = am.copy()\n",
    "df_seg['segment'] = labels\n",
    "\n",
    "# Add other static features: capacity, ratings, price_summary\n",
    "# (we assume you already ran build_umap_and_distances or similar)\n",
    "# here we recompute price_mean, price_std from df_prices for simplicity:\n",
    "price_summary = (\n",
    "    df_prices\n",
    "    .groupby(\"ID\")['Value']\n",
    "    .agg(price_mean='mean', price_std='std')\n",
    ")\n",
    "# merge them in\n",
    "df_seg = (\n",
    "    df_seg\n",
    "    .merge(price_summary, left_index=True, right_index=True)\n",
    "    .merge(df_attr.set_index('ID')[['Person capacity']], left_index=True, right_index=True)\n",
    "    .dropna()  # drop any listings missing fields\n",
    ")\n",
    "\n",
    "X = df_seg.drop(columns='segment').values\n",
    "y = df_seg['segment'].astype(int).values  # convert to int for sklearn\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# --- 1) Multinomial Logistic Regression ------------------------------------\n",
    "\n",
    "log_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000))\n",
    "])\n",
    "log_pipe.fit(X_train, y_train)\n",
    "y_pred_log = log_pipe.predict(X_test)\n",
    "\n",
    "print(\"=== Multinomial Logistic Regression ===\")\n",
    "print(classification_report(y_test, y_pred_log, zero_division=0))\n",
    "\n",
    "# --- 2) Gradient Boosting --------------------------------------------------\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=0)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "print(\"=== Gradient Boosting ===\")\n",
    "print(classification_report(y_test, y_pred_gb, zero_division=0))\n",
    "\n",
    "# --- 3) Interpretable Decision Tree ----------------------------------------\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"=== Decision Tree (depth=4) ===\")\n",
    "print(classification_report(y_test, y_pred_dt, zero_division=0))\n",
    "\n",
    "# Print the textual tree for interpretation:\n",
    "feature_names = df_seg.drop(columns='segment').columns.tolist()\n",
    "print(\"\\nLearned Decision Tree rules:\\n\")\n",
    "print(export_text(dt, feature_names=feature_names))\n",
    "\n",
    "# --- 4) Confusion Matrices (optional) --------------------------------------\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for name, y_pred in [('LogReg', y_pred_log), ('GB', y_pred_gb), ('DT', y_pred_dt)]:\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57c27b",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, hamming_loss\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 1) BUILD FEATURE MATRIX X and MULTI-LABEL TARGET Y -----------------------\n",
    "\n",
    "# static features from Attributes\n",
    "static_feats = df_attr.set_index(\"ID\")[\n",
    "    [\"Base fee\", \"Cleaning fee\", \"Bedrooms\", \"Beds\", \"Baths\"] +\n",
    "    [c for c in df_attr.columns if c.endswith(\"_rating\")]\n",
    "]\n",
    "\n",
    "# volatility features\n",
    "vol_feats = compute_volatility_features()\n",
    "\n",
    "# UMAP coords\n",
    "df_space, _, _, _ = build_umap_and_distances()\n",
    "umap_feats = df_space.set_index(\"ID\")[[\"UMAP1\", \"UMAP2\", \"UMAP3\"]]\n",
    "\n",
    "# price_time_series summaries\n",
    "# (already computed in build_umap_and_distances as price_mean, price_std, price_trend)\n",
    "# but if not, recompute quickly:\n",
    "price_summary = (\n",
    "    df_prices\n",
    "    .groupby(\"ID\")['Value']\n",
    "    .agg(price_mean=lambda x: np.log1p(x).mean(),\n",
    "         price_std = lambda x: np.log1p(x).std(),\n",
    "         price_trend=lambda x: LinearRegression()\n",
    "                              .fit(\n",
    "                                  (pd.to_datetime(df_prices.loc[x.index,\"Date\"]) \n",
    "                                   - pd.to_datetime(df_prices.loc[x.index,\"Date\"]).min()\n",
    "                                  ).dt.days.values.reshape(-1,1),\n",
    "                                  np.log1p(x)\n",
    "                              ).coef_[0]\n",
    "        )\n",
    ")\n",
    "\n",
    "# combine all numeric features\n",
    "X = (\n",
    "    static_feats\n",
    "    .join(vol_feats, how=\"inner\")\n",
    "    .join(umap_feats, how=\"inner\")\n",
    "    .join(price_summary, how=\"inner\")\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "# multi-label target: selected amenities one-hot\n",
    "amenities = [\n",
    "    \"Wifi\",\"Kitchen\",\"Washer\",\"Dryer\",\"Air conditioning\",\"Heating\",\n",
    "    \"TV\",\"Jacuzzi\",\"Elevator\",\"Patio or balcony\"\n",
    "]\n",
    "Y = df_attr.set_index(\"ID\")[amenities].loc[X.index].astype(int)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 2) MODEL A: MultiOutput Random Forest --------------------------------------\n",
    "\n",
    "rf = MultiOutputClassifier(\n",
    "    Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=200, random_state=0))\n",
    "    ])\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = pd.DataFrame(rf.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "print(\"== Random Forest MultiOutput ==\")\n",
    "print(\"Hamming loss:\", hamming_loss(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
    "\n",
    "\n",
    "# 3) MODEL B: One-vs-Rest Logistic Regression -------------------------------\n",
    "\n",
    "ovr = OneVsRestClassifier(\n",
    "    Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('lr', LogisticRegression(solver='liblinear'))\n",
    "    ])\n",
    ")\n",
    "ovr.fit(X_train, y_train)\n",
    "y_pred_ovr = pd.DataFrame(ovr.predict(X_test), index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "print(\"== One-vs-Rest Logistic ==\")\n",
    "print(\"Hamming loss:\", hamming_loss(y_test, y_pred_ovr))\n",
    "print(classification_report(y_test, y_pred_ovr, zero_division=0))\n",
    "\n",
    "\n",
    "# 4) MODEL C: Deep MLP with Sigmoid Outputs ---------------------------------\n",
    "\n",
    "# build a simple MLP\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "mlp = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(output_dim, activation='sigmoid')\n",
    "])\n",
    "mlp.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xtr = scaler.transform(X_train)\n",
    "Xte = scaler.transform(X_test)\n",
    "\n",
    "# train\n",
    "mlp.fit(Xtr, y_train.values, \n",
    "        validation_split=0.1, epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# predict (threshold at 0.5)\n",
    "y_prob = mlp.predict(Xte)\n",
    "y_pred_mlp = (y_prob > 0.5).astype(int)\n",
    "y_pred_mlp = pd.DataFrame(y_pred_mlp, index=y_test.index, columns=y_test.columns)\n",
    "\n",
    "print(\"== Deep MLP ==\")\n",
    "print(\"Hamming loss:\", hamming_loss(y_test, y_pred_mlp))\n",
    "print(classification_report(y_test, y_pred_mlp, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
